

<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<style>
@media (prefers-color-scheme: dark) {
    body {
        background-color: #1c1c1c;
        color: white;
    }
    .markdown-body table tr {
        background-color: #1c1c1c;
    }
    .markdown-body table tr:nth-child(2n) {
        background-color: black;
    }
}
</style>



<link rel="alternate" type="application/rss+xml" href="../../../../feed.xml" title="The Triangle of Harm">



<link rel="stylesheet" type="text/css" href="../../../../css/common-vendor.b8ecfc406ac0b5f77a26.css">
<link rel="stylesheet" type="text/css" href="../../../../css/fretboard.f32f2a8d5293869f0195.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty.0ae3265014f89d9850bf.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty-vendor.83ac49e057c3eac4fce3.css">
<link rel="stylesheet" type="text/css" href="../../../../css/global.css">
<link rel="stylesheet" type="text/css" href="../../../../css/misc.css">

<script type="text/x-mathjax-config">
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  },
  svg: {
    fontCache: 'global',
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="../../../../scripts/tex-svg.js">
</script>

<style>
</style>

<div id="doc" class="container-fluid markdown-body comment-enabled" data-hard-breaks="true">

<div id="color-mode-switch">
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />
  </svg>
  <input type="checkbox" id="switch" />
  <label for="switch">Dark Mode Toggle</label>
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
  </svg>
</div>

<script type="text/javascript">
  // Update root html class to set CSS colors
  const toggleDarkMode = () => {
    const root = document.querySelector('html');
    root.classList.toggle('dark');
  }

  // Update local storage value for colorScheme
  const toggleColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    if (colorScheme === 'light') localStorage.setItem('colorScheme', 'dark');
    else localStorage.setItem('colorScheme', 'light');
  }

  // Set toggle input handler
  const toggle = document.querySelector('#color-mode-switch input[type="checkbox"]');
  if (toggle) toggle.onclick = () => {
    toggleDarkMode();
    toggleColorScheme();
  }

  // Check for color scheme on init
  const checkColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    // Default to light for first view
    if (colorScheme === null || colorScheme === undefined) localStorage.setItem('colorScheme', 'light');
    // If previously saved to dark, toggle switch and update colors
    if (colorScheme === 'dark') {
      toggle.checked = true;
      toggleDarkMode();
    }
  }
  checkColorScheme();
</script>

<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="The Triangle of Harm" />
<meta name="twitter:image" content="http://vitalik.eth.limo/images/icon.png" />


<br>
<h1 style="margin-bottom:7px"> The Triangle of Harm </h1>
<small style="float:left; color: #888"> 2017 Jul 16 </small>
<small style="float:right; color: #888"><a href="../../../../index.html">See all posts</a></small>
<br> <br> <br>
<title> The Triangle of Harm </title>

The following is a diagram from a slide that I made in one of my
presentations at Cornell this week: <br><br>
<center>
<img src="../../../../images/triangle-of-harm-files/triangle_of_harm.png" style="width:420px" class="padded" />
</center>
<p><br><br> If there was one diagram that could capture the core
principle of Casper's incentivization philosophy, this might be it.
Hence, it warrants some further explanation.</p>
<p>The diagram shows three constituencies - the minority, the majority
and the protocol (ie. users), and four arrows representing possible
adversarial actions: the minority attacking the protocol, the minority
attacking the majority, the majority attacking the protocol, and the
majority attacking the minority. Examples of each include:</p>
<ul>
<li><strong>Minority attacking the protocol</strong> - <a
href="https://bitcoin.stackexchange.com/questions/4942/what-is-a-finney-attack">Finney
attacks</a> (an attack done by a miner on a proof of work blockchain
where the miner double-spends unconfirmed, or possibly single-confirmed,
transactions)</li>
<li><strong>Minority attacking the majority</strong> - <a
href="https://bitcointalk.org/index.php?topic=312668.0">feather
forking</a> (a minority in a proof of work chain attempting to revert
any block that contains some undesired transactions, though giving up if
the block gets two confirmations)</li>
<li><strong>Majority attacking the protocol</strong> - traditional 51%
attacks</li>
<li><strong>Majority attacking the minority</strong> - a 51% censorship
attack, where a cartel refuses to accept any blocks from miners (or
validators) outside the cartel</li>
</ul>
<p>The essence of Casper's philosophy is this: <strong>for all four
categories of attack</strong>, we want to put an upper bound on the
ratio between the amount of harm suffered by the victims of the attack
and the cost to the attacker. In some ways, every design decision in
Casper flows out of this principle.</p>
<p>This differs greatly from the usual proof of work incentivization
school of thought in that in the proof of work view, the last two
attacks are left undefended against. The first two attacks, Finney
attacks and feather forking, are costly because the attacker risks their
blocks not getting included into the chain and so loses revenue. If the
attacker is a majority, however, the attack is costless, because the
attacker can always guarantee that their chain will be the main chain.
In the long run, difficulty adjustment ensures that the total revenue of
all miners is exactly the same no matter what, and this further means
that if an attack causes some victims to lose money, then the attacker
<em>gains</em> money.</p>
<p>This property of proof of work arises because traditional Nakamoto
proof of work fundamentally <em>punishes dissent</em> - if you as a
miner make a block that aligns with the consensus, you get rewarded, and
if you make a block that does not align with the consensus you get
penalized (the penalty is not in the protocol; rather, it comes from the
fact that such a miner expends electricity and capital to produce the
block and gets no reward).</p>
Casper, on the other hand, works primarily by <em>punishing
equivocation</em> - if you send two messages that conflict with each
other, then you get very heavily penalized, even if one of those
messages aligns with the consensus (read more on this in the <a
href="https://medium.com/@VitalikButerin/minimal-slashing-conditions-20f0b500fc6c">blog
post on "minimal slashing conditions"</a>). Hence, in the event of a
finality reversion attack, those who caused the reversion event are
penalized, and everyone else is left untouched; the majority can attack
the protocol only at heavy cost, and the majority cannot cause the
minority to lose money. <br>
<hr />
<p><br></p>
<p>It gets more challenging when we move to talking about two other
kinds of attacks - liveness faults, and censorship. A liveness fault is
one where a large portion of Casper validators go offline, preventing
the consensus from reaching finality, and a censorship fault is one
where a majority of Casper validators refuse to accept some
transactions, or refuse to accept consensus messages from other Casper
validators (the victims) in order to deprive them of rewards.</p>
<p>This touches on a fundamental dichotomy: <strong>speaker/listener
fault equivalence</strong>.</p>
<br><br>
<center>
<img src="../../../../images/triangle-of-harm-files/mouthshut.jpg" style="height:300px"></img>
<img src="../../../../images/triangle-of-harm-files/canthearyou.jpg" style="height:300px; margin-left:100px"></img>
</center>
<p><br><br></p>
<p>Suppose that person B says that they did not receive a message from
person A. There are two possible explanations: (i) person A did not send
the message, (ii) person B pretended not to hear the message. Given just
the evidence of B's claim, <em>there is no way to tell which of the two
explanations is correct</em>. The relation to blockchain protocol
incentivization is this: if you see a protocol execution where 70% of
validators' messages are included in the chain and 30% are not, and see
nothing else (and this is what the blockchain sees), then there is no
way to tell whether the problem is that 30% are offline or 70% are
censoring. If we want to make both kinds of attacks expensive, there is
only one thing that we can do: <strong>penalize both sides</strong>.</p>
<p>Penalizing both sides allows either side to "grief" the other, by
going offline if they are a minority and censoring if they are a
majority. However, we can establish bounds on how easy this griefing is,
through the technique of <strong>griefing factor analysis</strong>. The
griefing factor of a strategy is essentially the amount of money lost by
the victims divided by the amount of money lost by the attackers, and
the griefing factor of a protocol is the highest griefing factor that it
allows. For example, if a protocol allows me to cause you to lose $3 at
a cost of $1 to myself, then the griefing factor is 3. If there are no
ways to cause others to lose money, the griefing factor is zero, and if
you can cause others to lose money at no cost to yourself (or at a
benefit to yourself), the griefing factor is infinity.</p>
<p>In general, <strong>wherever a speaker/listener dichotomy exists, the
griefing factor cannot be globally bounded above by any value below
1</strong>. The reason is simple: either side can grief the other, so if
side <span class="math inline">\(A\)</span> can grief side <span
class="math inline">\(B\)</span> with a factor of <span
class="math inline">\(x\)</span> then side <span
class="math inline">\(B\)</span> can grief side <span
class="math inline">\(A\)</span> with a factor of <span
class="math inline">\(\frac{1}{x}\)</span>; <span
class="math inline">\(x\)</span> and <span
class="math inline">\(\frac{1}{x}\)</span> cannot both be below 1
simultaneously. We can play around with the factors; for example, it may
be considered okay to allow griefing factors of 2 for majority attackers
in exchange for keeping the griefing factor at 0.5 for minorities, with
the reasoning that minority attackers are more likely. We can also allow
griefing factors of 1 for small-scale attacks, but specifically for
large-scale attacks force a chain split where on one chain one side is
penalized and on another chain another side is penalized, trusting the
market to pick the chain where attackers are not favored. Hence there is
a lot of room for compromise and making tradeoffs between different
concerns within this framework.</p>
<p>Penalizing both sides has another benefit: it ensures that if the
protocol is harmed, the attacker is penalized. This ensures that whoever
the attacker is, they have an incentive to avoid attacking that is
commensurate with the amount of harm done to the protocol. However, if
we want to bound the ratio of harm to the protocol over cost to
attackers, we need a formalized way of measuring how much harm to the
protocol was done.</p>
<p>This introduces the concept of the <strong>protocol utility
function</strong> - a formula that tells us how well the protocol is
doing, that should ideally be calculable from inside the blockchain. In
the case of a proof of work chain, this could be the percentage of all
blocks produced that are in the main chain. In Casper, protocol utility
is zero for a perfect execution where every epoch is finalized and no
safety failures ever take place, with some penalty for every epoch that
is not finalized, and a very large penalty for every safety failure. If
a protocol utility function can be formalized, then penalties for faults
can be set as close to the loss of protocol utility resulting from those
faults as possible.</p>
 </div> 