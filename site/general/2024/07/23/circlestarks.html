

<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<style>
@media (prefers-color-scheme: dark) {
    body {
        background-color: #1c1c1c;
        color: white;
    }
    .markdown-body table tr {
        background-color: #1c1c1c;
    }
    .markdown-body table tr:nth-child(2n) {
        background-color: black;
    }
}
</style>



<link rel="alternate" type="application/rss+xml" href="../../../../feed.xml" title="Exploring circle STARKs">



<link rel="stylesheet" type="text/css" href="../../../../css/main.css">

<script type="text/x-mathjax-config">
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  },
  svg: {
    fontCache: 'global',
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="../../../../scripts/tex-svg.js">
</script>

<style>
</style>

<div id="doc" class="container-fluid markdown-body comment-enabled" data-hard-breaks="true">

<div id="color-mode-switch">
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />
  </svg>
  <input type="checkbox" id="switch" />
  <label for="switch">Dark Mode Toggle</label>
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
  </svg>
</div>

<script type="text/javascript">
  // Update root html class to set CSS colors
  const toggleDarkMode = () => {
    const root = document.querySelector('html');
    root.classList.toggle('dark');
  }

  // Update local storage value for colorScheme
  const toggleColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    if (colorScheme === 'light') localStorage.setItem('colorScheme', 'dark');
    else localStorage.setItem('colorScheme', 'light');
  }

  // Set toggle input handler
  const toggle = document.querySelector('#color-mode-switch input[type="checkbox"]');
  if (toggle) toggle.onclick = () => {
    toggleDarkMode();
    toggleColorScheme();
  }

  // Check for color scheme on init
  const checkColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    // Default to light for first view
    if (colorScheme === null || colorScheme === undefined) localStorage.setItem('colorScheme', 'light');
    // If previously saved to dark, toggle switch and update colors
    if (colorScheme === 'dark') {
      toggle.checked = true;
      toggleDarkMode();
    }
  }
  checkColorScheme();
</script>

<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Exploring circle STARKs" />
<meta name="twitter:image" content="http://vitalik.ca/images/icon.png" />


<br>
<h1 style="margin-bottom:7px"> Exploring circle STARKs </h1>
<small style="float:left; color: #888"> 2024 Jul 23 </small>
<small style="float:right; color: #888"><a href="../../../../index.html">See all posts</a></small>
<br> <br> <br>
<title> Exploring circle STARKs </title>

<p><em>This article assumes familiarity with the basics of how SNARKs
and STARKs work; if you are not familiar, I recommend the first few
sections in <a
href="https://vitalik.eth.limo/general/2024/04/29/binius.html">this
article</a>. Special thanks to Eli ben-Sasson, Shahar Papini, Avihu Levy
and others at starkware for feedback and discussion.</em></p>
<p>The most important trend in STARK protocol design over the last two
years has been the switch to working over small fields. The earliest
production implementations of STARKs worked over 256-bit fields -
arithmetic modulo large numbers such as <code>21888...95617</code> <span
class="math inline">\(\approx 1.51 * 2^{253}\)</span> - which made these
protocols naturally compatible with verifying elliptic curve-based
signatures, and made them easy to reason about. But this led to
inefficiency: in most cases we don't actually have good ways to make use
of these larger numbers, and so they ended up as mostly wasted space,
and even more wasted computation, since arithmetic over 4x bigger
numbers takes <a
href="https://en.wikipedia.org/wiki/Karatsuba_algorithm">~9x more</a>
computation time. To deal with this, STARKs have started working over
smaller fields: first <a
href="https://polygon.technology/blog/plonky2-a-deep-dive">Goldilocks</a>
(modulus <span class="math inline">\(2^{64} - 2^{32} + 1\)</span>) and
then <a
href="https://blog.icme.io/small-fields-for-zero-knowledge/">Mersenne31
and BabyBear</a> (<span class="math inline">\(2^{31} - 1\)</span> and
<span class="math inline">\(2^{31} - 2^{27} + 1\)</span>,
respectively).</p>
<p>This switch has already led to demonstrated massive improvements in
proving speed, most notably Starkware being able to <a
href="https://x.com/StarkWareLtd/status/1807776563188162562">prove
620,000 Poseidon2 hashes per second</a> on an M3 laptop. Particularly,
this means that, provided we're willing to trust Poseidon2 as a hash
function, one of the hardest parts of making an efficient <a
href="https://vitalik.eth.limo/general/2022/08/04/zkevm.html">ZK-EVM</a>
is effectively solved. But how do these techniques work, and how do
cryptographic proofs, which typically require large numbers for
security, get built over these fields? And how do these protocols
compare to even more exotic <a
href="https://vitalik.eth.limo/general/2024/04/29/binius.html">constructions</a>
such as <a
href="https://www.irreducible.com/posts/binius-hardware-optimized-snark">Binius</a>?
This post will explore some of these nuances, with a particular eye to a
construction called <a href="https://eprint.iacr.org/2024/278">Circle
STARKs</a> (implemented in Starkware's <a
href="https://github.com/starkware-libs/stwo">stwo</a>, Polygon's <a
href="https://github.com/Plonky3/Plonky3">plonky3</a>, and <a
href="https://github.com/ethereum/research/tree/master/circlestark">my
own implementation in (sort of) python</a>), which has some unique
properties designed to be compatible with the highly efficient
Mersenne31 field.</p>
<h2 id="issues-common-to-small-fields">Issues common to small
fields</h2>
<p>One of the most important "tricks" when making hash-based proofs (or
really, any kind of proof) is the idea of proving things about
evaluations of a polynomial as a random point, as a substitute for
proving things about the underlying polynomials.</p>
<p>For example, suppose that a proof system requires you to generate a
commitment to a polynomial, <span class="math inline">\(A\)</span>,
which must satisfy <span class="math inline">\(A^3(x) + x - A(\omega*x)
= x^N\)</span> (a pretty common type of claim to prove in ZK-SNARK
protocols). The protocol can require you to pick a random coordinate
<span class="math inline">\(r\)</span>, and prove that <span
class="math inline">\(A(r) + r - A(\omega*r) = r^N\)</span>. And then in
turn, to prove that <span class="math inline">\(A(r) = c\)</span>, you
prove that <span class="math inline">\(Q = \frac{A - c}{X - r}\)</span>
is a polynomial (as opposed to a fractional expression).</p>
<p>If you know <span class="math inline">\(r\)</span> <em>ahead of
time</em>, you can always cheat these protocols. In this case, you could
just set <span class="math inline">\(A(r)\)</span> to be zero, retrofit
<span class="math inline">\(A(\omega * r)\)</span> to satisfy the
equation, and then let <span class="math inline">\(A\)</span> be the
line that passes through those two points. And similarly for the second
step, if you know <span class="math inline">\(r\)</span> ahead of time,
you can generate whatever <span class="math inline">\(Q\)</span> you
want, and then retrofit <span class="math inline">\(A\)</span> to match
it, even if <span class="math inline">\(A\)</span> is a fractional (or
other non-polynomial) expression.</p>
<p>To prevent these attacks, we need to choose <span
class="math inline">\(r\)</span> <em>after</em> the attacker provides
<span class="math inline">\(A\)</span> (the <a
href="https://en.wikipedia.org/wiki/Fiat%E2%80%93Shamir_heuristic">"Fiat-Shamir
heuristic"</a> is a fancy name for setting <span
class="math inline">\(r\)</span> to be the <em>hash</em> of <span
class="math inline">\(A\)</span>). Importantly, <strong>we need to
choose <span class="math inline">\(r\)</span> from a set large enough
that the attacker cannot guess it</strong>.</p>
<p>In elliptic curve based protocols and even 2019-era STARKs, this was
trivial: all of our math was done over 256-bit numbers, so we choose
<span class="math inline">\(r\)</span> as a random 256-bit number, and
we're fine. With STARKs over smaller fields, we have a problem: there
are only about two billion possible values of <span
class="math inline">\(r\)</span> to choose from, and so an attacker
wanting to make a fake proof need only try two billion times - a lot of
work, but quite doable for a determined attacker!</p>
<p>There are two natural solutions to this problem:</p>
<ul>
<li>Perform <strong>multiple random checks</strong></li>
<li><strong>Extension fields</strong></li>
</ul>
<p>The approach of performing multiple random checks is intuitively
appealing and simple: instead of checking at <em>one</em> coordinate,
you repeat the check at each of <em>four</em> random coordinates. This
is theoretically doable, but there is an efficiency issue. If you're
dealing with degree &lt; <span class="math inline">\(N\)</span>
polynomials over a size <span class="math inline">\(p\)</span> field,
it's actually possible for an attacker to craft bad polynomials that
"look" good in <span class="math inline">\(N\)</span> positions. Hence,
their chance of breaking one round of the protocol is <span
class="math inline">\(\frac{N}{p}\)</span>. If eg. <span
class="math inline">\(p = 2^{31} - 1\)</span> and <span
class="math inline">\(N = 2^{24}\)</span>, that means the attacker only
gets seven bits of security per round, and so you need to do not four,
but around 18 rounds, to be properly robust against such attackers.
Ideally, we would have something where we do <span
class="math inline">\(k\)</span> times more work but only have to
subtract <span class="math inline">\(N\)</span> from the security level
<em>once</em>.</p>
<p>This gets us to the other solution: <strong>extension
fields</strong>. Extension fields are like complex numbers, but over
finite fields: we imagine into existence a new value, call it <span
class="math inline">\(i\)</span>, and declare that <span
class="math inline">\(i^2 = -1\)</span>. Multiplication <a
href="https://www2.clarku.edu/faculty/djoyce/complex/mult.html">becomes</a>:
<span class="math inline">\((a+bi) * (c+di) = (ac - bd) + (ad +
bc)i\)</span>. We can now operate over <em>pairs</em> <span
class="math inline">\((a,b)\)</span> rather than just single numbers.
Assuming we're working over size <span class="math inline">\(\approx
2^{31}\)</span> fields like Mersenne or BabyBear, this gets us up to
having <span class="math inline">\(\approx 2^{62}\)</span> values from
which to choose <span class="math inline">\(r\)</span>. To go even
higher, we apply the same technique again, except we already used <span
class="math inline">\(i\)</span> so we need to define a new value
differently: in Mersenne31, we pick <span
class="math inline">\(w\)</span> where <span class="math inline">\(w^2 =
-2i-1\)</span>. Multiplication now becomes <span
class="math inline">\((a + bi + cw + diw) * (e + fi + gw + hiw) =
...\)</span></p>
<center>
<p><br></p>
<p><a
href="https://github.com/ethereum/research/blob/master/circlestark/fields.py"><img
src="https://hackmd.io/_uploads/BJ5nW2i80.png" /></a></p>
<p><small><i>OK fine, here's the code implementation. It's not optimal
(you can improve it with <a
href="https://en.wikipedia.org/wiki/Karatsuba_algorithm">Karatsuba</a>),
but it shows the principles.</i></small></p>
</center>
<p><br></p>
<p>Now, we have <span class="math inline">\(\approx 2^{124}\)</span>
values to choose <span class="math inline">\(r\)</span> from, which is
high enough for our security needs: if we are dealing with degree &lt;
<span class="math inline">\(2^{20}\)</span> polynomials, we get 104 bits
of security from one round. If we want to be paranoid and go up to the
more widely-accepted 128 bit security level, we can add some proof of
work into the protocol.</p>
<p>Note that we only actually use this extension field in the FRI
protocol, and other cases where random linear combinations are required.
The bulk of the math is done over only the "base field" (modulo <span
class="math inline">\(2^{31}-1\)</span> or <span
class="math inline">\(15 * 2^{27} + 1\)</span>), and almost all of the
data that is hashed is over the base field, so you only hash four bytes
per value. This lets us both benefit from the efficiency of small
fields, and retain the ability to dip into a larger field when we need
to do so for security.</p>
<h2 id="regular-fri">Regular FRI</h2>
<p>When building a SNARK or STARK, the first step is typically
arithmetization: reducing an arbitrary computation problem into an
equation where some of the variables and coefficients are polynomials
(eg. the equation often looks like <span class="math inline">\(C(T(x),
T(next(x))) = Z(x) * H(x)\)</span>, where <span
class="math inline">\(C\)</span>, <span
class="math inline">\(next\)</span> and <span
class="math inline">\(Z\)</span> are provided and the solver needs to
provide <span class="math inline">\(T\)</span> and <span
class="math inline">\(H\)</span>). Once you have such an equation, a
solution to the equation corresponds to a solution to the underlying
computational problem.</p>
<p>To prove that you have a solution, you need to prove that the values
that you are proposing actually are real polynomials (as opposed to
fractions, or datasets that look like one polynomial in one place and a
different polynomial in another place, or...), and have a certain maximum
degree. In order to do this, we apply a random linear combination trick
iteratively:</p>
<ul>
<li>Suppose you have evaluations of a polynomial <span
class="math inline">\(A\)</span>, and you want to prove that its degree
is <span class="math inline">\(&lt; 2^{20}\)</span></li>
<li>Consider the polynomials <span class="math inline">\(B(x^2) = A(x) +
A(-x)\)</span>, and <span class="math inline">\(C(x^2) = \frac{A(x) -
A(-x)}{x}\)</span>.</li>
<li>Let <span class="math inline">\(D\)</span> be a random linear
combination <span class="math inline">\(B + rC\)</span></li>
</ul>
<p>Essentially, what's going on is that <span
class="math inline">\(B\)</span> isolates the even coefficients of <span
class="math inline">\(A\)</span>, and <span
class="math inline">\(C\)</span> isolates the odd coefficients. Given
<span class="math inline">\(B\)</span> and <span
class="math inline">\(C\)</span>, you can recover <span
class="math inline">\(A\)</span>: <span class="math inline">\(A(x) =
B(x^2) + xC(x^2)\)</span>. And if <span class="math inline">\(A\)</span>
really has degree <span class="math inline">\(&lt; 2^{20}\)</span>, then
(i) <span class="math inline">\(B\)</span> and <span
class="math inline">\(C\)</span> have degree <span
class="math inline">\(&lt; 2^{19}\)</span>. And being a random linear
combination, <span class="math inline">\(D\)</span> must also have
degree <span class="math inline">\(&lt; 2^{19}\)</span>.</p>
<p>We've reduced a "prove degree <span class="math inline">\(&lt;
2^{20}\)</span>" problem into a "prove degree <span
class="math inline">\(&lt; 2^{19}\)</span>" problem. Repeat this 20
times, and you get the technique that is called "<a
href="https://eccc.weizmann.ac.il/report/2017/134/">Fast Reed-Solomon
Interactive Oracle Proofs of Proximity</a>", or "FRI". If someone tries
to push something through this technique which is <em>not</em> a degree
<span class="math inline">\(&lt; 2^{20}\)</span> polynomial, then the
second-round output will (with probability <span
class="math inline">\(\approx 1 - \frac{1}{2^{124}}\)</span>) not be a
degree <span class="math inline">\(&lt; 2^{19}\)</span> polynomial, the
third-round output will not be degree <span class="math inline">\(&lt;
2^{18}\)</span>, and so on, and the final check at the end will fail. A
dataset which is equal to a degree <span class="math inline">\(&lt;
2^{20}\)</span> polynomial in <em>most</em> positions has some chance of
passing through the scheme, but in order to construct such a dataset you
need to know the underlying polynomial, so even such a
slightly-defective proof is a convincing argument that the prover could
generate a "real" proof if they wanted to. There are further technical
complexities in proving that this holds for <em>all</em> possible
inputs; understanding the fine details of this has been a major focus of
academic STARK research over the last five years.</p>
<p>Let's look into what's going on here in more detail, and what
properties are necessary to make this all work. At each step, we're
reducing the <em>degree</em> by a factor of 2, and we're also reducing
the <em>domain</em> (the set of points we're looking at) by a factor of
2. The former is what makes FRI work at all. The latter is what makes it
so blazing fast: because each round is 2x smaller than the previous, the
total cost is <span class="math inline">\(O(N)\)</span> instead of <span
class="math inline">\(O(N*log(N))\)</span>.</p>
<p>To do this domain reduction, we needed a <em>two-to-one map</em>:
<span class="math inline">\(\{x, -x\} \rightarrow x^2\)</span>. What's
nice about this two-to-one map is that it's repeatable: if you start
with a <em>multiplicative subgroup</em> (a set <span
class="math inline">\(\{1, \omega, \omega^2 ...
\omega^{n-1}\}\)</span>), then you start off with a set where for any
<span class="math inline">\(x\)</span> in the set, <span
class="math inline">\(-x\)</span> is also in the set (as if <span
class="math inline">\(x = \omega^k\)</span>, <span
class="math inline">\(-x = \omega^{k\pm\frac{N}{2}}\)</span>), and if
you then square it to get <span class="math inline">\(\{1, (\omega^2),
(\omega^2)^2 ... (\omega^2)^{\frac{n}{2}-1}\}\)</span>, then the exact
same property applies, and so you can keep reducing all the way down to
one value (though in practice we usually stop a little bit earlier).</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/HkRZnghIC.png" /></p>
</center>
<p><br></p>
<p>You can think of this as being an operation of taking a line that
goes around a circle, and stretching that line until it makes two
rotations along that circle. A point at x degrees becomes a point at 2x
degrees. Each point from 0...179 degrees has a corresponding point at
180...359 degrees that it ends up overlapping with. And you can repeat
this procedure again and again.</p>
<p>For this to work, you need the original multiplicative subgroup to
have a size with a large power of 2 as a product. BabyBear has modulus
<span class="math inline">\(15 * 2^{27} + 1\)</span>, and so the largest
possible subgroup is all nonzero values - hence, size <span
class="math inline">\(15 * 2^{27}\)</span>. This is very friendly to the
above technique. You could take a subgroup of size <span
class="math inline">\(2^{27}\)</span>, or you could just take that full
set, do the FRI to reduce the polynomial all the way down to degree 15,
and then check tthe degree directly at the end. Mersenne31, however,
does not work in this way. The modulus is <span
class="math inline">\(2^{31} - 1\)</span>, and so the multiplicative
subgroup has size <span class="math inline">\(2^{31} - 2\)</span>. This
can be divided by 2 only once. From there forward, we have no way to do
an FFT - at least not using the technique above.</p>
<p>This is a tragedy, because Mersenne31 is a <em>super-convenient</em>
field to do arithmetic in using existing 32-bit CPU/GPU operations. If
you add two numbers, the result may be above <span
class="math inline">\(2^{31}-1\)</span>, but you can reduce it by doing
<span class="math inline">\(x \rightarrow x + (x &gt;&gt; 31)\)</span>,
where <span class="math inline">\(&gt;&gt;\)</span> is a bit shift. For
multiplication, you can do something similar, though you need to use a
special (but commonly available) opcode that returns the "high-order
bits" of a multiplication result (ie. <span
class="math inline">\(floor(\frac{xy}{2^{32}})\)</span>). This allows
arithmetic to be around 1.3x more efficient than BabyBear. If we
<em>could</em> do FRI over Mersenne31, it would make things
significantly better for us.</p>
<h2 id="circle-fri">Circle FRI</h2>
<p>Here is where the clever trick of <a
href="https://elibensasson.blog/why-im-excited-by-circle-stark-and-stwo/">circle
STARKs</a> comes in. Given a prime <span
class="math inline">\(p\)</span>, it turns out that we also have easy
access to a group of size <span class="math inline">\(p+1\)</span> that
has similar two-to-one properties: the set of points <span
class="math inline">\((x,y)\)</span> where <span
class="math inline">\(x^2 + y^2 = 1\)</span>. Let's look at this
structure modulo 31:</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/S19YGbh8C.png" /></p>
</center>
<p><br></p>
<p>The points follow an addition law, which might feel very familiar if
you've recently done either <a
href="https://mathworld.wolfram.com/TrigonometricAdditionFormulas.html">trigonometry</a>
or <a
href="https://unacademy.com/content/cbse-class-11/study-material/mathematics/algebra-of-complex-numbers-multiplication/">complex
multiplication</a>:</p>
<p><span class="math inline">\((x_1, y_1) + (x_2, y_2) = (x_1x_2 -
y_1y_2, x_1y_2 + x_2y_1)\)</span></p>
<p>The doubling form is:</p>
<p><span class="math inline">\(2 * (x, y) = (2x^2 - 1, 2xy)\)</span></p>
<p>Now, let's focus on <em>only</em> the points that are in "odd"
positions on this circle:</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/SJBxN-3UR.png" /></p>
</center>
<p><bw></p>
<p>Now, here is our FFT. First, we collapse all the points down to a
single line. Our equivalent of the <span
class="math inline">\(B(x^2)\)</span> and <span
class="math inline">\(C(x^2)\)</span> formulas that we had in regular
FRI is:</p>
<center>
<p><span class="math inline">\(f_0(x) = \frac{F(x,y) +
F(x,-y)}{2}\)</span> <span class="math inline">\(f_1(x) = \frac{F(x,y) -
F(x,-y)}{2y}\)</span></p>
</center>
<p>We can then take a random linear combination, and we get a
one-dimensional <span class="math inline">\(F\)</span> that is over a
subset of the x line:</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/HkGiSb28A.png" /></p>
</center>
<p><br></p>
<p>From the second round onward, the map changes:</p>
<center>
<p><span class="math inline">\(f_0(2x^2-1) = \frac{F(x) +
F(-x)}{2}\)</span> <span class="math inline">\(f_1(2x^2-1) = \frac{F(x)
- F(-x)}{2x}\)</span></p>
</center>
<p>And this map actually takes the above set, and reduces its size in
half each time! What is going on here is that each <span
class="math inline">\(x\)</span> is in some sense "standing in" for two
points: <span class="math inline">\((x,y)\)</span> and <span
class="math inline">\((x,-y)\)</span>. And <span class="math inline">\(x
\rightarrow 2x^2-1\)</span> is the point doubling law above. Hence, we
take the <span class="math inline">\(x\)</span> coordinate of two
opposite points on the circle, and convert it into the <span
class="math inline">\(x\)</span> coordinate of the doubled point.</p>
<p>For example, if we take the second-rightmost value, <span
class="math inline">\(2\)</span>, and apply the map, we get <span
class="math inline">\(2(2^2) - 1 = 7\)</span>. If we go back to the
original circle, <span class="math inline">\((2,11)\)</span> is the
third point going counterclockwise from the right, and so if we double
it, we get the sixth point going counterclockwise from the right, which
is... <span class="math inline">\((7, 13)\)</span>.</p>
<p>This <em>could have</em> all been done two-dimensionally, but
operating over one dimension makes things more efficient.</p>
<h2 id="circle-ffts">Circle FFTs</h2>
<p>An algorithm closely related to FRI is the <a
href="https://vitalik.eth.limo/general/2019/05/12/fft.html">fast Fourier
transform</a>, which takes a set of <span
class="math inline">\(n\)</span> evaluations of a degree <span
class="math inline">\(&lt; n\)</span> polynomial and converts it into
the <span class="math inline">\(n\)</span> coefficients of the
polynomial. An FFT follows the same path as a FRI, except instead of
generating a random linear combination <span
class="math inline">\(f_0\)</span> and <span
class="math inline">\(f_1\)</span> at each step, it just recursively
applies a half-sized FFT on both, and then takes the output of <span
class="math inline">\(FFT(f_0)\)</span> as the even coefficients and
<span class="math inline">\(FFT(f_1)\)</span> as the odd
coefficients.</p>
<p>The circle group also supports an FFT, which is also constructed from
FRI along similar lines. However, <strong>a key difference is that the
objects that circle FFTs (and circle FRI) work over are not technically
polynomials</strong>. Rather, they are what mathematicians call a <a
href="https://en.wikipedia.org/wiki/Riemann%E2%80%93Roch_theorem">Riemann-Roch
space</a>: in this case, polynomials "modulo" the circle (<span
class="math inline">\(x^2 + y^2 - 1 = 0\)</span>). That is, we treat any
multiple of <span class="math inline">\(x^2 + y^2 - 1\)</span> as being
equal to zero. Another way of thinking about it is: we only allow
degree-1 powers of <span class="math inline">\(y\)</span>: as soon as we
get a <span class="math inline">\(y^2\)</span> term, we replace it with
<span class="math inline">\(1 - x^2\)</span>.</p>
<p>One other thing that this implies is that the "coefficients" that a
circle FFT outputs are not monomials like in regular FRI (eg. if regular
FRI outputs <span class="math inline">\([6, 2, 8, 3]\)</span>, then we
know this means <span class="math inline">\(P(x) = 3x^3 + 8x^2 + 2x =
6\)</span>). Instead, the coefficients are in a strange basis specific
to circle FFTs:</p>
<p><span class="math inline">\(\{1, y, x, xy, 2x^2-1, 2x^2y-y, 2x^3-x,
2x^3y-xy, 8 x^4 - 8 x^2 + 1...\}\)</span></p>
<p>The good news is that as a developer, you can almost completely
ignore this. STARKs never give you a need to know the coefficients.
Instead, you can just always store "polynomials" as a set of evaluations
on a particular domain. The only place you need to use FFTs, is to
perform (the Riemann-Roch space analogue of) <em>low-degree
extension</em>: given <span class="math inline">\(N\)</span> values,
generate <span class="math inline">\(k*N\)</span> values that are on
that same polynomial. In that case, you can do an FFT to generate the
coefficients, append <span class="math inline">\((k-1)n\)</span> zeroes
to those coefficients, and then do an inverse-FFT to get back your
larger set of evaluations.</p>
<p>Circle FFTs are not the only type of "exotic FFT". <a
href="https://www.researchgate.net/publication/353344649_Elliptic_Curve_Fast_Fourier_Transform_ECFFT_Part_I_Fast_Polynomial_Algorithms_over_all_Finite_Fields">Elliptic
curve FFTs</a> are even more powerful, because they work over
<em>any</em> finite field (prime, binary, etc). However, ECFFTs are even
more complex to understand and less efficient, and so because we can use
circle FFTs for <span class="math inline">\(p = 2^{31}-1\)</span>, we
do.</p>
<p>From here, let's get into some of the more esoteric minutiae that
will be different for someone implementing circle STARKs, as compared to
regular STARKs.</p>
<h2 id="quotienting">Quotienting</h2>
<p>A common thing that you do in STARK protocols is you take quotients
at specific points, either deliberately chosen or randomly chosen. For
example, if you want to prove that <span class="math inline">\(P(x) =
y\)</span>, you do so by providing <span class="math inline">\(Q =
\frac{P - y}{X - x}\)</span>, and proving that <span
class="math inline">\(Q\)</span> is a polynomial (as opposed to a
fractional value). Randomly choosing evaluation points is used in the <a
href="https://eprint.iacr.org/2019/336">DEEP-FRI protocol</a>, which
lets FRI be secure with fewer Merkle branches.</p>
<p>Here, we get to one subtle challenge: <em>in the circle group, there
is no line function, analogous to <span class="math inline">\(X -
x\)</span> for regular FRI, that passes through only one point</em>.
This is visible geometrically:</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/S1E-mMnIR.png" /></p>
</center>
<p><br></p>
<p>You could make a line function <em>tangent</em> to one point <span
class="math inline">\((P_x, P_y)\)</span>, but that would pass through
the point "with multiplicity 2" - that is, for a polynomial to be a
multiple of that line function, it would have to fulfill a much stricter
condition than just being zero at that point. Hence, you can't prove an
evaluation at only one point. So what do we do? Basically, we bite the
bullet, and prove an evaluation at <em>two</em> points, adding a dummy
point whose evaluation we don't need to care about.</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/SJaUNM2IC.png" /></p>
<p><small><i>A line function: <span class="math inline">\(ax + by +
c\)</span>. If you turn it into an equation by forcing it to equal 0,
then you might recognize it as a line in <a
href="https://www.khanacademy.org/math/algebra/x2f8bb11595b61c86:forms-of-linear-equations/x2f8bb11595b61c86:standard-form/v/standard-form-for-linear-equations">what
high school math calls "standard form"</a>.</i></small></p>
</center>
<p><br></p>
<p>If we have a polynomial <span class="math inline">\(P\)</span> that
equals <span class="math inline">\(v_1\)</span> at <span
class="math inline">\(P_1\)</span>, and <span
class="math inline">\(v_2\)</span> at <span
class="math inline">\(P_2\)</span>, then we choose an
<em>interpolant</em> <span class="math inline">\(I\)</span>: a line
function that equals <span class="math inline">\(v_1\)</span> at <span
class="math inline">\(P_1\)</span>, and <span
class="math inline">\(v_2\)</span> at <span
class="math inline">\(P_2\)</span>. This can be as simple as <span
class="math inline">\(v_1 + (v_2 - v_1) * \frac{y - y_1}{(P_2)_y -
(P_1)_y}\)</span>. We then prove that <span
class="math inline">\(P\)</span> equals <span
class="math inline">\(v_1\)</span> at <span
class="math inline">\(P_1\)</span>, and <span
class="math inline">\(v_2\)</span> at <span
class="math inline">\(P_2\)</span> by subtracting <span
class="math inline">\(I\)</span> (so <span
class="math inline">\(P-I\)</span> equals zero at both points), dividing
by <span class="math inline">\(L\)</span> (the line function between
<span class="math inline">\(P_1\)</span> and <span
class="math inline">\(P_2\)</span>), and proving that the quotient <span
class="math inline">\(\frac{P - I}{L}\)</span> is a polynomial.</p>
<h2 id="vanishing-polynomials">Vanishing polynomials</h2>
<p>In a STARK, the polynomial equation you're trying to prove often
looks like <span class="math inline">\(C(P(x), P(next(x))) = Z(x) *
H(x)\)</span>, where <span class="math inline">\(Z(x)\)</span> is a
polynomial that equals zero across your entire original evaluation
domain. In "regular" STARKs, that function is just <span
class="math inline">\(x^n - 1\)</span>. In circle STARKs, you the
equivalent is:</p>
<center>
<p><span class="math inline">\(Z_1(x,y) = y\)</span></p>
<p><span class="math inline">\(Z_2(x,y) = x\)</span></p>
<p><span class="math inline">\(Z_{n+1}(x,y) = (2 * Z_n(x,y)^2) -
1\)</span></p>
</center>
<p>Notice that you can derive the vanishing polynomial from the folding
function: in regular STARKs, you're repeating <span
class="math inline">\(x \rightarrow x^2\)</span>, here you're repeating
<span class="math inline">\(x \rightarrow 2x^2-1\)</span>, though you're
doing something different for the first round, because the first round
is special.</p>
<h2 id="reverse-bit-order">Reverse bit order</h2>
<p>In STARKs, evaluations of a polynomial are typically arranged not in
the "natural" order (<span class="math inline">\(P(1)\)</span>, <span
class="math inline">\(P(\omega)\)</span>, <span
class="math inline">\(P(\omega^2)\)</span> ... <span
class="math inline">\(P(\omega^{n-1})\)</span>), but rather what I call
"reverse bit order":</p>
<center>
<p><span class="math inline">\(P(1)\)</span>, <span
class="math inline">\(P(\omega^{\frac{n}{2}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{n}{4}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{3n}{4}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{n}{8}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{5n}{8}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{3n}{8}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{7n}{8}})\)</span>, <span
class="math inline">\(P(\omega^{\frac{n}{16}})\)</span>...</p>
</center>
<p>If we set <span class="math inline">\(n = 16\)</span>, and we focus
just on which powers of <span class="math inline">\(\omega\)</span>
we're evaluating at, the list looks like this:</p>
<center>
<p><span class="math inline">\(\{0, 8, 4, 12, 2, 10, 6, 14, 1, 9, 5, 13,
3, 11, 7, 15\}\)</span></p>
</center>
<p>This ordering has the key property that values which get grouped
together early on in a FRI evaluation are put beside each other in the
ordering. For example, the first step of FRI groups together <span
class="math inline">\(x\)</span> and <span
class="math inline">\(-x\)</span>. In the <span
class="math inline">\(n=16\)</span> case, <span
class="math inline">\(\omega^8 = -1\)</span>, so that means <span
class="math inline">\(P(\omega^i)\)</span> and <span
class="math inline">\(P(-\omega^i) = P(\omega^{i+8})\)</span>. And, as
we can see, those are exactly the pairs that are right beside each
other. The second step of FRI groups together <span
class="math inline">\(P(\omega^i)\)</span>, <span
class="math inline">\(P(\omega^{i+4})\)</span>, <span
class="math inline">\(P(\omega^{i+8})\)</span> and <span
class="math inline">\(P(\omega^{i+12})\)</span>. And, those are exactly
the groups of four that we see. And so forth. This makes FRI much more
space-efficient, because it lets you provide one Merkle proof for both
of the values that get folded together (or, if you fold <span
class="math inline">\(k\)</span> rounds at a time, all <span
class="math inline">\(2^k\)</span> of the values) simultaneously.</p>
<p>In circle STARKs, the folding structure is a bit different: in the
first step we group together <span class="math inline">\((x, y)\)</span>
with <span class="math inline">\((x, -y)\)</span>, in the second step
<span class="math inline">\(x\)</span> with <span
class="math inline">\(-x\)</span>, and in subsequent steps <span
class="math inline">\(p\)</span> with <span
class="math inline">\(q\)</span>, selecting <span
class="math inline">\(p\)</span> and <span
class="math inline">\(q\)</span> such that <span
class="math inline">\(Q^i(p) = -Q^i(q)\)</span> where <span
class="math inline">\(Q^i\)</span> is the map <span
class="math inline">\(x \rightarrow 2x^2-1\)</span> repeated <span
class="math inline">\(i\)</span> times. If we think of the points in
terms of their position along the circle, at each step this looks like
the first point getting paired with the last, the second with the second
last, etc.</p>
<p>To adjust reverse bit order to reflect this folding structure, we
reverse every bit <em>except the last</em>. We keep the last bit, and we
also use it to determine whether or not to flip the other bits.</p>
<center>
<p><br></p>
<p><img src="../../../../images/circlestarks/ryDRpDhuR.png" /></p>
</center>
<p><br></p>
<p>A size-16 folded reverse bit order looks as follows:</p>
<center>
<p><span class="math inline">\(\{0, 15, 8, 7, 4, 11, 12, 3, 2, 13, 10,
5, 6, 9, 14, 1\}\)</span></p>
</center>
<p>If you look at the circle in the previous section, the 0th, 15th, 8th
and 7th points (going counterclockwise, starting from the right) are of
the form <span class="math inline">\((x, y)\)</span>, <span
class="math inline">\((x, -y)\)</span>, <span class="math inline">\((-x,
-y)\)</span> and <span class="math inline">\((-x, y)\)</span>, which is
exactly what we need.</p>
<h2 id="efficiency">Efficiency</h2>
<p>Circle STARKs (and 31-bit-prime STARKs in general) are very
efficient. A realistic computation that is being proven in a circle
STARK would most likely involve a few types of computation:</p>
<ol type="1">
<li>Native arithmetic, used for "business logic" such as counting</li>
<li>Native arithmetic, used for cryptography (eg. hash functions like <a
href="https://eprint.iacr.org/2023/323">Poseidon</a>)</li>
<li><a href="https://eprint.iacr.org/2023/1518">Lookup arguments</a>, a
generic way to do many kinds of computation efficiently by implementing
them via reading values from tables</li>
</ol>
<p>The key measure of efficiency is: are you using the entire space in
the computational trace to do useful work, or are you leaving a lot of
wasted space? In large-field SNARKs, there is a lot of wasted space:
business logic and lookup tables mostly involve computation over small
numbers (often the numbers are under N in an N-step computation, so
under <span class="math inline">\(2^{25}\)</span> in practice), but you
have to pay the cost of using a size <span
class="math inline">\(2^{256}\)</span>-bit field anyway. Here, the field
is size <span class="math inline">\(2^{31}\)</span>, so the wasted space
is not large. "Designed-for-SNARKs" low-arithmetic-complexity hashes
(eg. Poseidon) use every bit of each number in the trace in any
field.</p>
<p>Hence, circle STARKs actually get pretty close to optimal! <a
href="https://vitalik.eth.limo/general/2024/04/29/binius.html">Binius</a>
is even stronger, because it lets you mix-and-match fields of different
sizes and thereby get even more efficient bit packing for everything.
Binius also opens up options for doing 32-bit addition without incurring
the overhead of lookup tables. However, those gains at the cost of (in
my opinion) significantly higher theoretical complexity, whereas circle
STARKs (and even more so BabyBear-based regular STARKs) are conceptually
quite simple.</p>
<h2 id="conclusion-what-do-i-think-about-circle-starks">Conclusion: what
do I think about circle STARKs?</h2>
<p>Circle STARKs don't impose <em>too many</em> extra complexities on
developers compared to regular STARKs. In the process of making an
implementation, the above three issues are essentially the <em>only</em>
differences that I saw compared to regular FRI. The underlying math
behind what the "polynomials" that circle FRI is operating on is quite
counterintuitive, and takes a while to understand and appreciate. But it
just so happens that this complexity is hidden away in such a way it's
not <em>that</em> visible to developers. The complexity of circle math
is <a
href="https://vitalik.eth.limo/general/2022/02/28/complexity.html">encapsulated,
not systemic</a>.</p>
<p>Understanding circle FRI and circle FFTs can also be a good
intellectual gateway to understanding other "exotic FFTs": most notably
<a
href="https://github.com/ethereum/research/blob/master/binius/binary_ntt.py#L60">binary-field
FFTs</a> as used in <a
href="https://vitalik.eth.limo/general/2024/04/29/binius.html">Binius</a>
and in <a href="https://github.com/elibensasson/libSTARK">LibSTARK</a>
before, and also spookier constructions such as <a
href="https://arxiv.org/abs/2107.08473">elliptic curve FFTs</a>, which
use few-to-1 maps that work nicely with elliptic curve point
operations.</p>
<p>With the combination of Mersenne31, BabyBear, and binary-field
techniques like Binius, it does feel like we are approaching the limits
of efficiency of the "base layer" of STARKs. At this point, I am
expecting the frontiers of STARK optimization to move to making
maximally-efficient arithmetizations of primitives like hash functions
and signatures (and optimizing those primitives themselves for that
purpose), making recursive constructions to enable more parallelization,
arithmetizing VMs to improve developer experience, and other
higher-level tasks.</p>
 </div> 