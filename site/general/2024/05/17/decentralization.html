

<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<style>
@media (prefers-color-scheme: dark) {
    body {
        background-color: #1c1c1c;
        color: white;
    }
    .markdown-body table tr {
        background-color: #1c1c1c;
    }
    .markdown-body table tr:nth-child(2n) {
        background-color: black;
    }
}
</style>



<link rel="alternate" type="application/rss+xml" href="../../../../feed.xml" title="The near and mid-term future of improving the Ethereum network's permissionlessness and decentralization">



<link rel="stylesheet" type="text/css" href="../../../../css/common-vendor.b8ecfc406ac0b5f77a26.css">
<link rel="stylesheet" type="text/css" href="../../../../css/fretboard.f32f2a8d5293869f0195.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty.0ae3265014f89d9850bf.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty-vendor.83ac49e057c3eac4fce3.css">
<link rel="stylesheet" type="text/css" href="../../../../css/global.css">
<link rel="stylesheet" type="text/css" href="../../../../css/misc.css">

<script type="text/x-mathjax-config">
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  },
  svg: {
    fontCache: 'global',
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="../../../../scripts/tex-svg.js">
</script>

<style>
</style>

<div id="doc" class="container-fluid markdown-body comment-enabled" data-hard-breaks="true">

<div id="color-mode-switch">
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />
  </svg>
  <input type="checkbox" id="switch" />
  <label for="switch">Dark Mode Toggle</label>
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
  </svg>
</div>

<script type="text/javascript">
  // Update root html class to set CSS colors
  const toggleDarkMode = () => {
    const root = document.querySelector('html');
    root.classList.toggle('dark');
  }

  // Update local storage value for colorScheme
  const toggleColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    if (colorScheme === 'light') localStorage.setItem('colorScheme', 'dark');
    else localStorage.setItem('colorScheme', 'light');
  }

  // Set toggle input handler
  const toggle = document.querySelector('#color-mode-switch input[type="checkbox"]');
  if (toggle) toggle.onclick = () => {
    toggleDarkMode();
    toggleColorScheme();
  }

  // Check for color scheme on init
  const checkColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    // Default to light for first view
    if (colorScheme === null || colorScheme === undefined) localStorage.setItem('colorScheme', 'light');
    // If previously saved to dark, toggle switch and update colors
    if (colorScheme === 'dark') {
      toggle.checked = true;
      toggleDarkMode();
    }
  }
  checkColorScheme();
</script>

<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="The near and mid-term future of improving the Ethereum network's permissionlessness and decentralization" />
<meta name="twitter:image" content="http://vitalik.ca/images/icon.png" />


<br>
<h1 style="margin-bottom:7px"> The near and mid-term future of improving the Ethereum network's permissionlessness and decentralization </h1>
<small style="float:left; color: #888"> 2024 May 17 </small>
<small style="float:right; color: #888"><a href="../../../../index.html">See all posts</a></small>
<br> <br> <br>
<title> The near and mid-term future of improving the Ethereum network's permissionlessness and decentralization </title>

<p><em>Special thanks to Dankrad Feist, Caspar Schwarz-Schilling and
Francesco for rapid feedback and review.</em></p>
<p>I am sitting here writing this on the final day of an Ethereum
developer interop in Kenya, where we made a large amount of progress
implementing and ironing out technical details of important upcoming
Ethereum improvements, most notably <a
href="https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541">PeerDAS</a>,
the <a href="https://verkle.info/">Verkle tree transition</a> and
decentralized approaches to storing history in the context of <a
href="https://eips.ethereum.org/EIPS/eip-4444">EIP 4444</a>. From my own
perspective, it feels like the pace of Ethereum development, and our
capacity to ship large and important features that meaningfully improve
the experience for node operators and (L1 and L2) users, is
increasing.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/upload_2b9db82459e86d2206be6282e3af9483.png" /></p>
<p><small><i>Ethereum client teams working together to ship the Pectra
devnet.</i></small></p>
</center>
<p><br></p>
<p>Given this greater technical capacity, one important question to be
asking is: <strong>are we building toward the right goals?</strong> One
prompt for thinking about this is a recent series of unhappy tweets from
the long-time Geth core developer Peter Szilagyi:</p>
<br>
<center>
<p><img
src="../../../../images/decentralization/upload_9faddc0f088e11458f1009b4d6bac86b.png" />
<img
src="../../../../images/decentralization/upload_d24f6d5bcf23ab48a8c120738685bd17.png" /></p>
</center>
<p><br></p>
<p>These are valid concerns. They are concerns that many people in the
Ethereum community have expressed. They are concerns that I have on many
occasions had personally. However, I also do not think that the
situation is anywhere near as hopeless as Peter's tweets imply; rather,
many of the concerns are already being addressed by protocol features
that are already in-progress, and many others can be addressed by very
realistic tweaks to the current roadmap.</p>
<p>In order to see what this means in practice, let us go through the
three examples that Peter provided one by one. The goal is not to focus
on Peter specifically; they are concerns that are widely shared among
many community members, and it's important to address them.</p>
<h2 id="mev-and-builder-dependence">MEV, and builder dependence</h2>
<p>In the past, Ethereum blocks were created by miners, who used a
relatively simple algorithm to create blocks. Users send transactions to
a public p2p network often called the "mempool" (or "txpool"). Miners
listen to the mempool, and accept transactions that are valid and pay
fees. They include the transactions they can, and if there is not enough
space, they prioritize by highest-fee-first.</p>
<p>This was a very simple system, and it was friendly toward
decentralization: as a miner, you can just run default software, and you
can get the same levels of fee revenue from a block that you could get
from highly professional mining farms. Around 2020, however, people
started exploiting what was called <strong>miner extractable value
(MEV)</strong>: revenue that could only be gained by executing complex
strategies that are aware of activities happening inside of various defi
protocols.</p>
<p>For example, consider decentralized exchanges like Uniswap. Suppose
that at time <code>T</code>, the USD/ETH exchange rate - on centralized
exchanges and on Uniswap - is $3000. At time <code>T+11</code>, the
USD/ETH exchange rate on centralized exchanges rises to $3005. But
Ethereum has not yet had its next block. At time <code>T+12</code>, it
does. Whoever creates the block can make their first transaction be a
series of Uniswap buys, buying up all of the ETH available on Uniswap at
prices from $3000 to $3004. This is extra revenue, and is called MEV.
Applications other than DEXes have their own analogues to this problem.
The <a href="https://arxiv.org/abs/1904.05234">Flash Boys 2.0 paper</a>
published in 2019 goes into this in detail.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/upload_20bedf3433084ded7d3d0254c860d97f.png" /></p>
<p><small><i>A chart from the Flash Boys 2.0 paper that shows the amount
of revenue capturable using the kinds of approaches described
above.</i></small></p>
<br>
</center>
<p>The problem is that this breaks the story for why mining (or,
post-2022, <strong>block proposing</strong>) can be "fair": now, large
actors who have better ability to optimize these kinds of extraction
algorithms can get a better return per block.</p>
<p>Since then there has been a debate between two strategies, which I
will call <strong>MEV minimization</strong> and <strong>MEV
quarantining</strong>. MEV minimization comes in two forms: (i)
aggressively work on MEV-free alternatives to Uniswap (eg. <a
href="https://swap.cow.fi/">Cowswap</a>), and (ii) build in-protocol
techniques, like encrypted mempools, that reduce the information
available to block producers, and thus reduce the revenue that they can
capture. In particular, encrypted mempools prevent strategies such as
<strong>sandwich attacks</strong>, which put transactions right before
and after users' trades in order to financially exploit them
("front-running").</p>
<p>MEV quarantining works by accepting MEV, but trying to limit its
impact on staking centralization by separating the market into two kinds
of actors: validators are responsible for attesting and proposing
blocks, but the task of <em>choosing the block's contents</em> gets
outsourced to specialized <strong>builders</strong> through an auction
protocol. Individual stakers now no longer need to worry about
optimizing defi arbitrage themselves; they simply join the auction
protocol, and accept the highest bid. This is called
<strong>proposer/builder separation (PBS)</strong>. This approach has
precedents in other industries: a major reason why restaurants are able
to remain so decentralized is that they often rely on a fairly
concentrated set of providers for various operations that do have large
economies of scale. So far, PBS has been reasonably successful at
ensuring that small validators and large validators are on a fair
playing field, at least as far as MEV is concerned. However, it creates
another problem: <strong>the task of choosing which transactions get
included becomes more concentrated</strong>.</p>
<p>My view on this has always been that MEV minimization is good and we
should pursue it (I personally use Cowswap regularly!) - though
encrypted mempools have a lot of challenges, but MEV minimization will
likely be insufficient; MEV will not go down to zero, or even near-zero.
Hence, we need some kind of MEV quarantining too. This creates an
interesting task: <strong>how do we make the "MEV quarantine box" as
small as possible</strong>? How do we give builders the least possible
power, while still keeping them capable of absorbing the role of
optimizing arbitrage and other forms of MEV collecting?</p>
<p>If builders have the power to exclude transactions from a block
entirely, there are attacks that can quite easily arise. Suppose that
you have a <a
href="https://coinmarketcap.com/academy/glossary/collateralized-debt-position-cdp">collateralized
debt position (CDP)</a> in a defi protocol, backed by an asset whose
price is rapidly dropping. You want to either bump up your collateral or
exit the CDP. Malicious builders could try to collude to refuse to
include your transaction, delaying it until prices drop by enough that
they can forcibly liquidate your CDP. If that happens, you would have to
pay a large penalty, and the builders would get a large share of it. So
how can we prevent builders from excluding transactions and
accomplishing these kinds of attacks?</p>
<p>This is where <strong>inclusion lists</strong> come in.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/17c9ae8c2f65fde9dbf814376563b338b1d0aff7.png" /></p>
<p><small><i>Source: <a
href="https://ethresear.ch/t/how-much-can-we-constrain-builders-without-bringing-back-heavy-burdens-to-proposers/13808">this
ethresear.ch post</a>.</i></small></p>
</center>
<p><br></p>
<p>Inclusion lists allow block proposers (meaning, stakers) to choose
transactions that are required to go into the block. Builders can still
reorder transactions or insert their own, but they must include the
proposer's transactions. Eventually, <a
href="https://eips.ethereum.org/EIPS/eip-7547">inclusion lists were
modified</a> to constrain the <em>next</em> block rather than the
current block. In either case, they take away the builder's ability to
push transactions out of the block entirely.</p>
<p>The above was all a deep rabbit hole of complicated background. But
MEV is a complicated issue; even the above description misses lots of
important nuances. As the old adage goes, "you may not be looking for
MEV, but MEV is looking for you". <strong>Ethereum researchers are
<em>already</em> quite aligned on the goal of "minimizing the quarantine
box", reducing the harm that builders can do (eg. by excluding or
delaying transactions as a way of attacking specific applications) as
much as possible.</strong></p>
<p>That said, I do think that we can go even further. Historically,
inclusion lists have often been conceived as an "off-to-the-side
special-case feature": normally, you would not think about them, but
just in case malicious builders start doing crazy things, they give you
a "second path". This attitude is reflected in current design decisions:
in the <a href="https://eips.ethereum.org/EIPS/eip-7547">current
EIP</a>, the gas limit of an inclusion list is around 2.1 million. But
we can make <strong>a philosophical shift in how we think about
inclusion lists: think of the inclusion list as <em>being the
block</em></strong>, and think of the builder's role as being an
off-to-the-side function of adding a few transactions to collect MEV.
What if it's <em>builders</em> that have the 2.1 million gas limit?</p>
<p>I think ideas in this direction - really pushing the quarantine box
to be as small as possible - are really interesting, and I'm in favor of
going in that direction. <strong>This <em>is</em> a shift from "2021-era
philosophy"</strong>: in 2021-era philosophy, we were more enthusiastic
about the idea that, since we now have builders, we can "overload" their
functionality and have them serve users in more complicated ways, eg. by
supporting <a href="https://www.erc4337.io/">ERC-4337 fee markets</a>.
In this new philosophy, the transaction validation parts of ERC-4337
would have to be enshrined into the protocol. Fortunately, the ERC-4337
team is already <a
href="https://notes.ethereum.org/@yoav/AA-roadmap-May-2024#Native-AA---a-modular-roadmap">increasingly
warm about this direction</a>.</p>
<p>Summary: MEV thought has <em>already</em> been going back in the
direction of empowering block producers, including giving block
producers the authority to directly ensure the inclusion of users'
transactions. Account abstraction proposals are <em>already</em> going
back in the direction of removing reliance on centralized relayers, and
even bundlers. However, there is a good argument that we are not going
far enough, and I think pressure pushing the development process to go
further in that direction is highly welcome.</p>
<h2 id="liquid-staking">Liquid staking</h2>
<p>Today, solo stakers make up a relatively small percentage of all
Ethereum staking, and most staking is done by various providers - some
centralized operators, and others DAOs, like Lido and RocketPool.</p>
<center>
<p><br></p>
<p><a href="https://dune.com/21co/ethereum-staking-and-withdrawals"><img
src="../../../../images/decentralization/upload_62f80a14ec8c47ca6bc94321a9719d3b.png" /></a></p>
</center>
<p><br></p>
<p>I have done my own research - various polls <a
href="https://warpcast.com/vitalik.eth/0x940d8535">[1]</a> <a
href="https://warpcast.com/vitalik.eth/0x5ff6b117">[2]</a>, surveys,
in-person conversations, asking the question "why are you - specifically
you - not solo staking today?" To me, a robust solo staking ecosystem is
by far my preferred outcome for Ethereum staking, and one of the best
things about Ethereum is that we actually try to support a robust solo
staking ecosystem instead of just surrendering to delegation. However,
we are far from that outcome. In my polls and surveys, there are a few
consistent trends:</p>
<ol type="1">
<li>The great majority of people who are not solo staking cite their
primary reason as being the 32 ETH minimum.</li>
<li>Out of those who cite other reasons, the highest is technical
challenge of running and maintaining a validator node.</li>
<li>The loss of instant availability of ETH, the security risks of "hot"
private keys, and the loss of ability to simultaneously participate in
defi protocols, are significant but smaller concerns.</li>
</ol>
<br>
<table>
<tr>
<td>
<p><img
src="../../../../images/decentralization/upload_ff62878744ee12ff1009dbfd7e345b0b.png" /></p>
</td>
<td>
<p><img
src="../../../../images/decentralization/upload_3e3500a63e892f8043f704b4192a40cf.png" /></p>
</td>
</tr>
</table>
<center>
<small><i>The main reasons why people are not solo staking, according to
Farcaster polls.</i></small>
</center>
<p><br></p>
<p>There are two key questions for staking research to resolve:</p>
<ol type="1">
<li>How do we solve these concerns?</li>
<li>If, despite effective solutions to most of these concerns, most
people <em>still</em> don't want to solo stake, how do we keep the
protocol stable and robust against attacks despite that fact?</li>
</ol>
<p>Many ongoing research and development items are aimed precisely at
solving these problems:</p>
<ol type="1">
<li><a href="https://verkle.info/">Verkle trees</a> plus <a
href="https://eips.ethereum.org/EIPS/eip-4444">EIP-4444</a> allow
staking nodes to function with very low hard disk requirements.
Additionallty, they allow staking nodes to sync almost instantly,
greatly simplifying the setup process, as well as operations such as
switching from one implementation to another. They also make Ethereum
light clients much more viable, by reducing the data bandwidth needed to
provide proofs for every state access.</li>
<li>Research <a
href="https://ethresear.ch/t/sticking-to-8192-signatures-per-slot-post-ssf-how-and-why/17989">(eg.
these proposals)</a> into ways to allow a much larger valdiator set
(enabling much smaller staking minimums) while at the same time reducing
consensus node overhead. These ideas can be implemented as part of <a
href="https://ethereum.org/en/roadmap/single-slot-finality/">single slot
finality</a>. Doing this would also makes light clients safer, as they
would be able to verify the full set of signatures instead of relying on
<a
href="https://github.com/ethereum/annotated-spec/blob/master/altair/sync-protocol.md">sync
committees</a>).</li>
<li>Ongoing Ethereum client optimizations keep reducing the cost and
difficulty of running a validator node, despite growing history.</li>
<li>Research on <a
href="https://x.com/yorickdowne/status/1750270987487097183">penalties
capping</a> could potentially mitigate concerns around private key risk,
and make it possible for stakers to simultaneously stake their ETH in
defi protocols if that's what they wish to do.</li>
<li><a
href="https://github.com/ethereum/annotated-spec/blob/master/capella/beacon-chain.md#blstoexecutionchange">0x01
Withdrawal credentials</a> allow stakers to set an ETH address as their
withdrawal address. This makes decentralized staking pools more viable,
giving them a leg up against centralized staking pools.</li>
</ol>
<p><strong>However, once again there is more that we could do</strong>.
It is theoretically possible to allow validators to withdraw much more
quickly: Casper FFG continues to be safe even if the validator set
changes by a few percent ever time it finalizes (ie. once per epoch).
Hence, we <em>could</em> reduce the withdrawal period much more if we
put effort into it. If we wanted to greatly reduce the minimum deposit
size, we <em>could</em> make a hard decision to trade off in other
directions, eg. if we increase the finality time by 4x, that would allow
a <a
href="https://medium.com/@VitalikButerin/parametrizing-casper-the-decentralization-finality-time-overhead-tradeoff-3f2011672735">4x
minimum deposit size decrease</a>. Single slot finality would later
clean this up by moving beyond the "every staker participates in every
epoch" model entirely.</p>
<p>Another important part of this whole question is <strong>the
economics of staking</strong>. A key question is: do we want staking to
be a relatively niche activity, or do we want everyone or almost
everyone to stake all of their ETH? If everyone is staking, then what is
the responsibility that we want everyone to take on? If people end up
simply delegating this responsibility because they are lazy, that could
end up leading to centralization. There are important and deep
philosophical questions here. Incorrect answers could lead Ethereum down
a path of centralization and "re-creating the traditional financial
system with extra steps"; correct answers could create a shining example
of a successful ecosystem with a wide and diverse set of solo stakers
and highly decentralized staking pools. These are questions that touch
on core Ethereum economics and values, and so we need more diverse
participation here.</p>
<h2 id="hardware-requirements-of-nodes">Hardware requirements of
nodes</h2>
<p>Many of the key questions in Ethereum decentralization end up coming
down to a question that has defined blockchain politics <a
href="https://www.coindesk.com/learn/what-is-the-bitcoin-block-size-debate-and-why-does-it-matter/">for
a decade</a>: <strong>how accessible do we want to make running a node,
and how?</strong></p>
<p>Today, running a node is hard. Most people do not do it. On the
laptop that I am using to write this post, I have a <a
href="https://github.com/paradigmxyz/reth">reth</a> node, and it takes
up 2.1 terabytes - already the result of heroic software engineering and
optimization. I needed to go and buy an extra 4 TB hard drive to put
into my laptop in order to store this node. We all want running a node
to be easier. In my ideal world, people would be able to run nodes on
their phones.</p>
<p>As I wrote above, EIP-4444 and Verkle trees are two key technologies
that get us closer to this ideal. If both are implemented, hardware
requirements of a node could plausibly eventually decrease to less than
a hundred gigabytes, and perhaps to near-zero if we eliminate the
history storage responsibility (perhaps only for non-staking nodes)
entirely. <a
href="https://vitalik.eth.limo/general/2022/08/04/zkevm.html">Type 1
ZK-EVMs</a> would remove the need to run EVM computation yourself, as
you could instead simply verify a proof that the execution was correct.
In my ideal world, we stack all of these technologies together, and even
Ethereum browser extension wallets (eg. Metamask, Rabby) have a built-in
node that verifies these proofs, does data availability sampling, and is
satisfied that the chain is correct.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/upload_e1a96a272fe0d1918574a89351aa1a9b.png" /></p>
<p><small><i>The vision described above is often called "The
Verge".</i></small></p>
</center>
<p><br></p>
<p>This is all known and understood, even by people raising the concerns
about Ethereum node size. However, there is an important concern:
<strong>if we are offloading the responsibility to maintain state and
provide proofs, then is that not a centralization vector? Even if they
can't cheat by providing <em>invalid data</em>, doesn't it still go
against the principles of Ethereum to get too dependent on
them?</strong></p>
<p>One very near-term version of this concern is <strong>many people's
discomfort toward EIP-4444: if regular Ethereum nodes no longer need to
store old history, then who does</strong>? A common answer is: there are
certainly enough big actors (eg. block explorers, exchanges, layer 2s)
who have the incentive to hold that data, and compared to <a
href="https://en.wikipedia.org/wiki/Wayback_Machine">the 100 petabytes
stored by the Wayback Machine</a>, the Ethereum chain is tiny. So it's
ridiculous to think that any history will actually be lost.</p>
<p>However, this arguments relies on dependence on a small number of
large actors. In my <a
href="https://vitalik.eth.limo/general/2020/08/20/trust.html">taxonomy
of trust models</a>, it's a 1-of-N assumption, but the N is pretty
small. This has its tail risks. One thing that we could do instead is to
<strong>store old history in a peer-to-peer network, where each node
only stores a small percentage of the data</strong>. This kind of
network would still do enough copying to ensure robustness: there would
be thousands of copies of each piece of data, and in the future we could
use erasure coding (realistically, by putting history into <a
href="https://www.eip4844.com/">EIP-4844</a>-style blobs, which already
have erasure coding built in) to increase robustness further.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/upload_baf4295d029cf62b9e2209fe9a441e19.png" /></p>
<p><small><i>Blobs have erasure coding <em>within blobs</em> and
<em>between blobs</em>. The easiest way to make ultra-robust storage for
<em>all</em> of Ethereum's history may well be to just put beacon and
execution blocks into blobs. <a
href="https://blog.codex.storage/data-availability-sampling/">Image
source: codex.storage</a></i></small></p>
</center>
<p><br></p>
<p>For a long time, this work has been on the backburner; <a
href="https://www.ethportal.net/">Portal Network</a> exists, but
realistically it has not gotten the level of attention commensurate with
its importance in Ethereum's future. Fortunately, there is now strong
interest in momentum toward putting far more resources into a minimized
version of Portal that focuses on distributed storage, and
accessibility, of history. This momentum should be built on, and we
should make a concerted effort to implement EIP-4444 soon, paired with a
robust decentralized peer-to-peer network for storing and retrieving old
history.</p>
<p>For state and ZK-EVMs, this kind of distributed approach is harder.
To build an efficient block, you simply have to have the full state. In
this case, I personally favor a pragmatic approach: <strong>we define,
and stick to, some level of hardware requirements needed to have a "node
that does everything", which is higher than the (ideally
ever-decreasing) cost of simply validating the chain, but still low
enough to be affordable to hobbyists.</strong> We rely on a 1-of-N
assumption, where we ensure that the N is quite large. For example, this
could be a high-end consumer laptop.</p>
<p>ZK-EVM proving is likely to be the trickiest piece, and real-time
ZK-EVM provers are likely to require considerably beefier hardware than
an archive node, even with <a
href="https://vitalik.eth.limo/general/2024/04/29/binius.html">advancements
like Binius</a>, and worst-case-bounding with <a
href="https://vitalik.eth.limo/general/2024/05/09/multidim.html">multidimensional
gas</a>. We <em>could</em> work hard on a distributed proving network,
where each node takes on the responsibility to prove eg. one percent of
a block's execution, and then the block producer only needs to aggregate
the hundred proofs at the end. Proof aggregation trees could help
further. But if this doesn't work well, then one other compromise would
be to allow the hardware requirements of proving to get higher, but make
sure that a "node that does everything" can verify Ethereum blocks
directly (without a proof), fast enough to effectively participate in
the network.</p>
<h2 id="conclusions">Conclusions</h2>
<p>I think it is actually true that 2021-era Ethereum thought became too
comfortable with offloading responsibilities to a small number of
large-scale actors, as long as some kind of market mechanism or zero
knowledge proof system existed to force the centralized actors to behave
honestly. Such systems often work well in the average case, but fail
catastrophically in the worst case.</p>
<center>
<p><br></p>
<p><img
src="../../../../images/decentralization/upload_e11227e1cca3b2a12fc01b87a95f3adc.jpeg" /></p>
<p><i>We're not doing this.</i></p>
</center>
<p><br></p>
<p>At the same time, I think it's important to emphasize that current
Ethereum protocol proposals have already significantly moved away from
that kind of model, and take the need for a truly decentralized network
much more seriously. Ideas around stateless nodes, MEV mitigations,
single-slot finality, and similar concepts, already are much further in
this direction. A year ago, the idea of doing data availability sampling
by piggy-backing on relays as semi-centralized nodes was seriously
considered. This year, we've moved beyond the need to do such things,
with surprisingly robust progress on <a
href="https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541">PeerDAS</a>.</p>
<p>But there is a lot that we could do to go further in this direction,
on all three axes that I talked about above, as well as many other
important axes. <a href="https://github.com/a16z/helios">Helios</a> has
made great progress in giving Ethereum an "actual light client". Now, we
need to get it included by default in Ethereum wallets, <em>and</em>
make RPC providers provide proofs along with their results so that they
can be validated, <em>and</em> extend light client technology to layer 2
protocols. If Ethereum is scaling via a rollup-centric roadmap, layer 2s
need to get the same security and decentralization guarantees as layer
1. In a rollup-centric world, there are many other things that we should
be taking more seriously; decentralized and efficient cross-L2 bridges
are one example of many. Many dapps get their logs through centralized
protocols, as Ethereum's native log scanning has become too slow. We
could improve on this with a dedicated decentralized sub-protocol; <a
href="https://notes.ethereum.org/@vbuterin/parallel_post_state_roots">here</a>
is one proposal of mine for how this could be done.</p>
<p>There is a near-unlimited number of blockchain projects aiming for
the niche of "we can be super-fast, we'll think about decentralization
later". I don't think Ethereum should be one of those projects. Ethereum
L1 can and certainly should be a strong base layer for layer 2 projects
that <em>do</em> take a hyper-scale approach, using Ethereum as a
backbone for decentralization and security. Even a layer-2-centric
approach requires layer 1 itself to have sufficient scalability to
handle a significant number of operations. But we should have deep
respect for the properties that make Ethereum unique, and continue to
work to maintain and improve on those properties as Ethereum scales.</p>
 </div> 