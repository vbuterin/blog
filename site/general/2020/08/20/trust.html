

<!DOCTYPE html>
<html>
<meta charset="UTF-8">
<style>
@media (prefers-color-scheme: dark) {
    body {
        background-color: #1c1c1c;
        color: white;
    }
    .markdown-body table tr {
        background-color: #1c1c1c;
    }
    .markdown-body table tr:nth-child(2n) {
        background-color: black;
    }
}
</style>



<link rel="alternate" type="application/rss+xml" href="../../../../feed.xml" title="Trust Models">



<link rel="stylesheet" type="text/css" href="../../../../css/common-vendor.b8ecfc406ac0b5f77a26.css">
<link rel="stylesheet" type="text/css" href="../../../../css/fretboard.f32f2a8d5293869f0195.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty.0ae3265014f89d9850bf.css">
<link rel="stylesheet" type="text/css" href="../../../../css/pretty-vendor.83ac49e057c3eac4fce3.css">
<link rel="stylesheet" type="text/css" href="../../../../css/global.css">
<link rel="stylesheet" type="text/css" href="../../../../css/misc.css">

<script type="text/x-mathjax-config">
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\(', '\)']]
  },
  svg: {
    fontCache: 'global',
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="../../../../scripts/tex-svg.js">
</script>

<style>
</style>

<div id="doc" class="container-fluid markdown-body comment-enabled" data-hard-breaks="true">

<div id="color-mode-switch">
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z" />
  </svg>
  <input type="checkbox" id="switch" />
  <label for="switch">Dark Mode Toggle</label>
  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
    <path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
  </svg>
</div>

<script type="text/javascript">
  // Update root html class to set CSS colors
  const toggleDarkMode = () => {
    const root = document.querySelector('html');
    root.classList.toggle('dark');
  }

  // Update local storage value for colorScheme
  const toggleColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    if (colorScheme === 'light') localStorage.setItem('colorScheme', 'dark');
    else localStorage.setItem('colorScheme', 'light');
  }

  // Set toggle input handler
  const toggle = document.querySelector('#color-mode-switch input[type="checkbox"]');
  if (toggle) toggle.onclick = () => {
    toggleDarkMode();
    toggleColorScheme();
  }

  // Check for color scheme on init
  const checkColorScheme = () => {
    const colorScheme = localStorage.getItem('colorScheme');
    // Default to light for first view
    if (colorScheme === null || colorScheme === undefined) localStorage.setItem('colorScheme', 'light');
    // If previously saved to dark, toggle switch and update colors
    if (colorScheme === 'dark') {
      toggle.checked = true;
      toggleDarkMode();
    }
  }
  checkColorScheme();
</script>

<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Trust Models" />
<meta name="twitter:image" content="http://vitalik.eth.limo/images/icon.png" />


<br>
<h1 style="margin-bottom:7px"> Trust Models </h1>
<small style="float:left; color: #888"> 2020 Aug 20 </small>
<small style="float:right; color: #888"><a href="../../../../index.html">See all posts</a></small>
<br> <br> <br>
<title> Trust Models </title>

<p>One of the most valuable properties of many blockchain applications
is <em>trustlessness</em>: the ability of the application to continue
operating in an expected way without needing to rely on a specific actor
to behave in a specific way even when their interests might change and
push them to act in some different unexpected way in the future.
Blockchain applications are never <em>fully</em> trustless, but some
applications are much closer to being trustless than others. If we want
to make practical moves toward trust minimization, we want to have the
ability to compare different degrees of trust.</p>
<p>First, my simple one-sentence definition of trust: <strong>trust is
the use of any assumptions about the behavior of other people</strong>.
If before the pandemic you would walk down the street without making
sure to keep two meters' distance from strangers so that they could not
suddenly take out a knife and stab you, that's a kind of trust: both
trust that people are very rarely completely deranged, and trust that
the people managing the legal system continue to provide strong
incentives against that kind of behavior. When you run a piece of code
written by someone else, you trust that they wrote the code honestly
(whether due to their own sense of decency or due to an economic
interest in maintaining their reputations), or at least that <em>there
exist</em> enough people checking the code that a bug would be found.
Not growing your own food is another kind of trust: trust that enough
people will realize that it's in <em>their</em> interests to grow food
so they can sell it to you. You can trust different sizes of groups of
people, and there are different kinds of trust.</p>
<p>For the purposes of analyzing blockchain protocols, I tend to break
down trust into four dimensions:</p>
<ul>
<li>How many people do you need to behave as you expect?</li>
<li>Out of how many?</li>
<li>What kinds of motivations are needed for those people to behave? Do
they need to be altruistic, or just profit seeking? Do they <a
href="../../../2017/05/08/coordination_problems.html">need to be
uncoordinated</a>?</li>
<li>How badly will the system fail if the assumptions are violated?</li>
</ul>
<p>For now, let us focus on the first two. We can draw a graph:</p>
<center>
<img src="../../../../images/trust/trustout.png" />
</center>
<p><br></p>
<p>The more green, the better. Let us explore the categories in more
detail:</p>
<ul>
<li><strong>1 of 1</strong>: there is exactly one actor, and the system
works if (and only if) that one actor does what you expect them to. This
is the traditional "centralized" model, and it is what we are trying to
do better than.</li>
<li><strong>N of N</strong>: the "dystopian" world. You rely on a whole
bunch of actors, <em>all</em> of whom need to act as expected for
everything to work, with no backups if any of them fail.</li>
<li><strong>N/2 of N</strong>: this is how blockchains work - they work
if the majority of the miners (or PoS validators) are honest. Notice
that N/2 of N becomes significantly more valuable the larger the N gets;
a blockchain with a few miners/validators dominating the network is much
less interesting than a blockchain with its miners/validators widely
distributed. That said, we want to improve on even this level of
security, hence the <a
href="../../../2020/08/17/philosophy.html">concern around surviving 51%
attacks</a>.</li>
<li><strong>1 of N</strong>: there are many actors, and the system works
as long as at least one of them does what you expect them to. Any system
based on fraud proofs falls into this category, as do trusted setups
though in that case the N is often smaller. Note that you do want the N
to be as large as possible!</li>
<li><strong>Few of N</strong>: there are many actors, and the system
works as long as at least some small fixed number of them do what you
expect them do. <a href="https://arxiv.org/abs/1809.09044">Data
availability checks</a> fall into this category.</li>
<li><strong>0 of N</strong>: the systems works as expected without any
dependence whatsoever on external actors. Validating a block by checking
it yourself falls into this category.</li>
</ul>
<p>While all buckets other than "0 of N" can be considered "trust", they
are very different from each other! Trusting that one particular person
(or organization) will work as expected is very different from trusting
that <em>some single person anywhere</em> will do what you expect them
to. "1 of N" is arguably much closer to "0 of N" than it is to "N/2 of
N" or "1 of 1". A 1-of-N model might perhaps feel like a 1-of-1 model
because it feels like you're going through a single actor, but the
reality of the two is <em>very</em> different: in a 1-of-N system, if
the actor you're working with at the moment disappears or turns evil,
you can just switch to another one, whereas in a 1-of-1 system you're
screwed.</p>
<p>Particularly, note that even the correctness of the software you're
running typically depends on a "few of N" trust model to ensure that if
there's bugs in the code someone will catch them. With that fact in
mind, trying really hard to go from 1 of N to 0 of N on some other
aspect of an application is often like making a reinforced steel door
for your house when the windows are open.</p>
<p>Another important distinction is: how does the system fail if your
trust assumption is violated? In blockchains, two most common types of
failure are <strong>liveness failure</strong> and <strong>safety
failure</strong>. A liveness failure is an event in which you are
temporarily unable to do something you want to do (eg. withdraw coins,
get a transaction included in a block, read information from the
blockchain). A safety failure is an event in which something actively
happens that the system was meant to prevent (eg. an invalid block gets
included in a blockchain).</p>
<p>Here are a few examples of trust models of a few blockchain layer 2
protocols. I use "<strong>small N</strong>" to refer to the set of
participants of the layer 2 system itself, and "<strong>big N</strong>"
to refer to the participants of the blockchain; the assumption is always
that the layer 2 protocol has a smaller community than the blockchain
itself. I also limit my use of the word "liveness failure" to cases
where coins are stuck for a significant amount of time; no longer being
able to use the system but being able to near-instantly withdraw does
not count as a liveness failure.</p>
<ul>
<li><strong>Channels</strong> (incl state channels, lightning network):
1 of 1 trust for liveness (your counterparty can temporarily freeze your
funds, though the harms of this can be mitigated if you split coins
between multiple counterparties), N/2 of big-N trust for safety (a
blockchain 51% attack can steal your coins)</li>
<li><strong>Plasma</strong> (assuming centralized operator): 1 of 1
trust for liveness (the operator can temporarily freeze your funds), N/2
of big-N trust for safety (blockchain 51% attack)</li>
<li><strong>Plasma</strong> (assuming semi-decentralized operator, eg.
DPOS): N/2 of small-N trust for liveness, N/2 of big-N trust for
safety</li>
<li><strong>Optimistic rollup</strong>: 1 of 1 or N/2 of small-N trust
for liveness (depends on operator type), N/2 of big-N trust for
safety</li>
<li><strong>ZK rollup</strong>: 1 of small-N trust for liveness (if the
operator fails to include your transaction, you can withdraw, and if the
operator fails to include your withdrawal immediately they cannot
produce more batches and you can self-withdraw with the help of any full
node of the rollup system); no safety failure risks</li>
<li><strong>ZK rollup</strong> (with <a
href="https://ethresear.ch/t/efficient-unassisted-exit-witness-generation-from-rollups/7776">light-withdrawal
enhancement</a>): no liveness failure risks, no safety failure
risks</li>
</ul>
<p>Finally, there is the question of incentives: does the actor you're
trusting need to be very altruistic to act as expected, only slightly
altruistic, or is being rational enough? Searching for fraud proofs is
"by default" slightly altruistic, though just how altruistic it is
depends on the complexity of the computation (see <a
href="https://eprint.iacr.org/2015/702.pdf">the verifier's dilemma</a>),
and there are ways to modify the game to make it rational.</p>
<p>Assisting others with withdrawing from a ZK rollup is rational if we
add a way to micro-pay for the service, so there is <em>really</em>
little cause for concern that you won't be able to exit from a rollup
with any significant use. Meanwhile, the greater risks of the other
systems can be alleviated if we <a
href="../../../2020/08/17/philosophy.html">agree as a community</a> to
<a
href="https://ethresear.ch/t/timeliness-detectors-and-51-attack-recovery-in-blockchains/6925">not
accept 51% attack chains</a> that revert too far in history or censor
blocks for too long.</p>
<p>Conclusion: when someone says that a system "depends on trust", ask
them in more detail what they mean! Do they mean 1 of 1, or 1 of N, or
N/2 of N? Are they demanding these participants be altruistic or just
rational? If altruistic, is it a tiny expense or a huge expense? And
what if the assumption is violated - do you just need to wait a few
hours or days, or do you have assets that are stuck forever? Depending
on the answers, your own answer to whether or not you want to use that
system might be very different.</p>
 </div> 